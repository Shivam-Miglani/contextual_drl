{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Object-Centered Models (LOCM) \n",
    "This code combines LOCM1 and LOCM2 algorithms and is last part of the pipeline that I use in my thesis to generate PDDL models from instructional texts.\n",
    "\n",
    "- Step 1: Find classes and make transition graphs.\n",
    "- Step 2: Get transistion sets from LOCM2 algorithm\n",
    "- Step 3: Create FSMs\n",
    "- Step 4: Perform Zero Analysis and add new FSM if necessary.\n",
    "- Step 5: Create and test hypothesis for state parameters\n",
    "- Step 6: Create and merge state parameters\n",
    "- Step 7: Remove parameter flaws\n",
    "- Step 8: Extract static preconditions\n",
    "- Step 9: Form action schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"locm_data/rocket_locmfeb.txt\" #name of the file containing action sequences\n",
    "input_file_name = \"locm_data/tea.txt\"\n",
    "input_file_name = \"locm_data/childsnack1.txt\"\n",
    "input_file_name = \"locm_data/fire_alarm1\"\n",
    "input_file_name = \"locm_data/woodworking.txt\"\n",
    "domain_name = input_file_name.split('/')[-1].split('.')[0] #domain name is the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woodworking\n"
     ]
    }
   ],
   "source": [
    "print(domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    '''\n",
    "    Read the input data and return list of action sequences.\n",
    "    Each sequence is a list of action-argumentlist tuples.\n",
    "    '''\n",
    "    file = open(input_file_name, 'r')\n",
    "    sequences = []\n",
    "    for line in file:\n",
    "        \n",
    "        actions = []\n",
    "        arguments = []\n",
    "        if line and not line.isspace() and len(line)>1:\n",
    "            sequence = line.rstrip(\"\\n\\r\").lstrip(\"\\n\\r\").lower() \n",
    "            action_defs = sequence.split(\"),\")\n",
    "\n",
    "            for action_def in action_defs:\n",
    "                action = action_def.split('(')[0].strip(\")\\n\\r\").strip()\n",
    "                argument = action_def.split('(')[1].strip(\")\\n\\r\")\n",
    "                actions.append(action.strip())\n",
    "                argument_list = argument.split(',')\n",
    "                argument_list = [x.strip() for x in argument_list]\n",
    "                #argument_list.insert(0,'zero')\n",
    "                arguments.append(argument_list)\n",
    "                \n",
    "            \n",
    "            actarg_tuples = zip(actions,arguments)\n",
    "            sequences.append(list(actarg_tuples))\n",
    "    return sequences\n",
    "\n",
    "def print_sequences(sequences):\n",
    "    for seq in sequences:\n",
    "        for action in seq:\n",
    "            print(action)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = read_file(input_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('do', ['planing'])\n",
      "('use', ['colour'])\n",
      "('increase', ['cost', 'plane'])\n",
      "('glaze', ['piece', 'wood'])\n",
      "('increase', ['cost', 'glaze'])\n",
      "('take', ['piece'])\n",
      "('do', ['planing'])\n",
      "('use', ['colour'])\n",
      "('increase', ['cost', 'plane'])\n",
      "('glaze', ['piece', 'wood'])\n",
      "('increase', ['cost', 'glaze'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sequences(sequences) #print first sequence actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences)) #print number of plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1: Find classes \n",
    "\n",
    "User can fix this easily \n",
    "#### Improvement 1 : User names the classes through user input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = set() # A transition is denoted by action_name + argument_number.\n",
    "arguments = set()\n",
    "actions = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions\n",
      "{'take', 'glaze', 'do', 'increase', 'use'}\n",
      "\n",
      "Transitions\n",
      "{'use.0', 'take.0', 'increase.0', 'do.0', 'increase.1', 'glaze.0', 'glaze.1'}\n",
      "\n",
      "Arguments/Objects\n",
      "{'cost', 'glaze', 'colour', 'planing', 'piece', 'wood', 'plane'}\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "    for actarg_tuple in seq:\n",
    "        actions.add(actarg_tuple[0])\n",
    "        for j, arg in enumerate(actarg_tuple[1]):\n",
    "            transitions.add(actarg_tuple[0]+\".\"+str(j))\n",
    "            arguments.add(arg)\n",
    "\n",
    "print(\"\\nActions\")\n",
    "print(actions)\n",
    "print(\"\\nTransitions\")\n",
    "print(transitions)\n",
    "print(\"\\nArguments/Objects\")\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actarg_dictionary(sequences):\n",
    "    d = defaultdict(list)\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            d[actarg_tuple[0]].append(actarg_tuple[1])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do - [['planing'], ['planing']]\n",
      "use - [['colour'], ['colour']]\n",
      "increase - [['cost', 'plane'], ['cost', 'glaze'], ['cost', 'plane'], ['cost', 'glaze']]\n",
      "glaze - [['piece', 'wood'], ['piece', 'wood']]\n",
      "take - [['piece']]\n"
     ]
    }
   ],
   "source": [
    "d = get_actarg_dictionary(sequences)\n",
    "for k,v in d.items():\n",
    "        print(\"{} - {}\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get classes util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(d):\n",
    "    # TODO incorporate word similarity in get classes.\n",
    "    c = defaultdict(set)\n",
    "    for k,v in d.items():\n",
    "        for arg_list in v:\n",
    "            for i,object in enumerate(arg_list):\n",
    "                c[k,i].add(object)\n",
    "\n",
    "    sets = c.values()\n",
    "    classes = []\n",
    "    # remove duplicate classes\n",
    "    for s in sets:\n",
    "        if s not in classes:\n",
    "            classes.append(s)\n",
    "\n",
    "    # now do pairwise intersections of all values. If intersection, combine them; then return the final sets.\n",
    "    classes_copy = list(classes)\n",
    "    while True:\n",
    "        combinations = list(itertools.combinations(classes_copy,2))\n",
    "        intersections_count = 0\n",
    "        for combination in combinations:\n",
    "            if combination[0].intersection(combination[1]):\n",
    "                intersections_count +=1\n",
    "\n",
    "                if combination[0] in classes_copy:\n",
    "                    classes_copy.remove(combination[0])\n",
    "                if combination[1] in classes_copy:\n",
    "                    classes_copy.remove(combination[1])\n",
    "                classes_copy.append(combination[0].union(combination[1]))\n",
    "\n",
    "        if intersections_count==0:\n",
    "            # print(\"no intersections left\")\n",
    "            break\n",
    "\n",
    "    return classes_copy\n",
    "\n",
    "# TODO: Can use better approach here. NER will help.\n",
    "def get_class_names(classes):\n",
    "    # Name the class to first object found ignoring the digits in it\n",
    "    class_names = []\n",
    "    for c in classes:\n",
    "        for object in c:\n",
    "#             object = ''.join([i for i in object if not i.isdigit()])\n",
    "            class_names.append(object)\n",
    "            break\n",
    "    return class_names\n",
    "\n",
    "def get_class_index(arg,classes):\n",
    "    for class_index, c in enumerate(classes):\n",
    "        if arg in c:\n",
    "            return class_index #it is like breaking out of the loop\n",
    "    print(\"Error:class index not found\") #this statement is only executed if class index is not returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorts/Classes\n",
      "[{'planing'}, {'colour'}, {'cost'}, {'plane', 'glaze'}, {'piece'}, {'wood'}]\n",
      "\n",
      "Extracted class names\n",
      "['planing', 'colour', 'cost', 'plane', 'piece', 'wood']\n"
     ]
    }
   ],
   "source": [
    "classes = get_classes(d) #sorts of object\n",
    "print(\"\\nSorts/Classes\")\n",
    "print(classes)\n",
    "\n",
    "class_names = get_class_names(classes)\n",
    "print(\"\\nExtracted class names\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed class names\n",
      "['planing', 'colour', 'cost', 'plane', 'piece', 'wood']\n"
     ]
    }
   ],
   "source": [
    "############ (Optional) User Input ############\n",
    "# Give user an option to change class names.\n",
    "# class_names[0] = 'rocket'\n",
    "# class_names[1] = 'cargo'\n",
    "# class_names[2] = 'sandwich'\n",
    "# class_names[0] = 'driver'\n",
    "# class_names[1] = 'truck'\n",
    "# class_names[2] = 'package'\n",
    "# class_names[3] = 'location'\n",
    "print(\"\\nRenamed class names\")\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions\n",
    "- Each object of a same class undergoes similar kind of transition.\n",
    "- Objects of same class in a same action undergo similar kind of transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions\n",
      "{'take', 'glaze', 'do', 'increase', 'use'}\n",
      "\n",
      "Transitions\n",
      "{'use.0', 'take.0', 'increase.0', 'do.0', 'increase.1', 'glaze.0', 'glaze.1'}\n",
      "{'glaze.wood.1', 'take.piece.0', 'increase.plane.1', 'use.colour.0', 'increase.cost.0', 'glaze.piece.0', 'do.planing.0'}\n",
      "\n",
      "Arguments/Objects\n",
      "{'cost', 'glaze', 'colour', 'planing', 'piece', 'wood', 'plane'}\n"
     ]
    }
   ],
   "source": [
    "# change transitions to be more meaningful by incorporating class_names.\n",
    "full_transitions = set()\n",
    "for seq in sequences:\n",
    "    for actarg_tuple in seq:\n",
    "        actions.add(actarg_tuple[0])\n",
    "        for j, arg in enumerate(actarg_tuple[1]):\n",
    "            full_transitions.add(actarg_tuple[0]+\".\"+class_names[get_class_index(arg,classes)]+\".\"+str(j))\n",
    "            arguments.add(arg)\n",
    "\n",
    "print(\"\\nActions\")\n",
    "print(actions)\n",
    "print(\"\\nTransitions\")\n",
    "print(transitions)\n",
    "print(full_transitions)\n",
    "print(\"\\nArguments/Objects\")\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Actions: 5,\n",
      "Number of unique transitions: 7,\n",
      "Number of unique objects (arguments): 7,\n",
      "Number of classes/sorts: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of Actions: {},\\nNumber of unique transitions: {},\\nNumber of unique objects (arguments): {},\\nNumber of classes/sorts: {}\".format(len(actions), len(transitions), len(arguments), len(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Make transition graphs\n",
    "\n",
    "User can fix these easily as well. (Cytoscape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Transition graph util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_transition_graphs(classes, domain_name, class_names):\n",
    "    # There should be a graph for each class of objects.\n",
    "    graphs = []  # number of graphs = number of sorts.\n",
    "    # Initialize all graphs empty\n",
    "    for sort in classes:\n",
    "        graphs.append(nx.DiGraph())\n",
    "\n",
    "    consecutive_transition_lists = [] #list of consecutive transitions per object instance per sequence.\n",
    "\n",
    "    for m, arg in enumerate(arguments):  # for all arguments (objects found in sequences)\n",
    "        for n, seq in enumerate(sequences):  # for all sequences\n",
    "            consecutive_transition_list = list()  # consecutive transition list for a sequence and an object (arg)\n",
    "            for i, actarg_tuple in enumerate(seq):\n",
    "                for j, arg_prime in enumerate(actarg_tuple[1]):  # for all arguments in actarg tuples\n",
    "                    if arg == arg_prime:  # if argument matches arg\n",
    "                        node = actarg_tuple[0] + \".\" +  str(j)\n",
    "#                         node = actarg_tuple[0] +  \".\" + class_names[get_class_index(arg,classes)] + \".\" +  str(j)  # name the node of graph which represents a transition\n",
    "                        consecutive_transition_list.append(node)  # add node to the cons_transition for sequence and argument\n",
    "\n",
    "                        # for each class append the nodes to the graph of that class\n",
    "                        class_index = get_class_index(arg_prime, classes)  # get index of class to which the object belongs to\n",
    "                        graphs[class_index].add_node(node)  # add node to the graph of that class\n",
    "\n",
    "            consecutive_transition_lists.append([n, arg, consecutive_transition_list])\n",
    "\n",
    "    # print(consecutive_transition_lists)\n",
    "    # for all consecutive transitions add edges to the appropriate graphs.\n",
    "    for cons_trans_list in consecutive_transition_lists:\n",
    "        # print(cons_trans_list)\n",
    "        seq_no = cons_trans_list[0]  # get sequence number\n",
    "        arg = cons_trans_list[1]  # get argument\n",
    "        class_index = get_class_index(arg, classes)  # get index of class\n",
    "        # add directed edges to graph of that class\n",
    "        for i in range(0, len(cons_trans_list[2]) - 1):\n",
    "                if graphs[class_index].has_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1]):\n",
    "                    graphs[class_index][cons_trans_list[2][i]][cons_trans_list[2][i + 1]]['weight'] += 1\n",
    "                else:\n",
    "                    graphs[class_index].add_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1], weight=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # make directory if doesn't exist\n",
    "    dirName = \"output/\"+ domain_name\n",
    "    if not os.path.exists(dirName):\n",
    "        os.makedirs(dirName)\n",
    "        print(\"Directory \", dirName, \" Created \")\n",
    "    else:\n",
    "        print(\"Directory \", dirName, \" already exists\")\n",
    "    empty_directory(dirName)\n",
    "\n",
    "\n",
    "    # plot and save all the graphs\n",
    "    adjacency_matrix_list = plot_and_save(graphs) # list of adjacency matrices per class\n",
    "\n",
    "    return adjacency_matrix_list\n",
    "\n",
    "def plot_and_save(graphs):\n",
    "    adjacency_matrix_list = [] # list of adjacency matrices per class\n",
    "    \n",
    "    for index, G in enumerate(graphs):\n",
    "        # TODO: Can use cytoscape or gephi for changes in Transition graphs (due to errors in data extracted).\n",
    "        nx.write_graphml(G, \"output/\"+ domain_name + \"/\" +  class_names[index] + \".graphml\")\n",
    "\n",
    "        nx.draw(G, arrow_style='fancy', with_labels=True)\n",
    "        labels = nx.get_edge_attributes(G, 'weight')\n",
    "        pos = nx.spring_layout(G)\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "        plt.show()\n",
    "        print(\"Nodes:{}\".format(G.nodes()))\n",
    "        print(\"Edges:{}\".format(G.edges()))\n",
    "\n",
    "        # TODO: save dataframes in cache and reload them.\n",
    "        # A = nx.to_numpy_matrix(G, nodelist=G.nodes())\n",
    "        \n",
    "        df = nx.to_pandas_adjacency(G, nodelist=G.nodes(), dtype=int)\n",
    "        adjacency_matrix_list.append(df)\n",
    "    return adjacency_matrix_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_directory(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            # elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))\n",
    "\n",
    "def print_table(matrix):\n",
    "    print(tabulate(matrix, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transition Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  output/woodworking  Created \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:['do.0']\n",
      "Edges:[('do.0', 'do.0')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:['use.0']\n",
      "Edges:[('use.0', 'use.0')]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAE1CAYAAACWU/udAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACxVJREFUeJzt3X+s1fV9x/HX/cG8F7iiQ0QsF5Q5S3rnUMuYEbJCFrP0SmwmSIGIMV3SOKdW/YOYYBNIRrKoWbMlVqdbNC3daMU5IWFxkvYuqwk6awKRSY2z6AUcRRAuUA7ce7n7Y+/dFKWYqkCVx+Ove74/PudzvsnJM9/vOfd8m4aGhoYCAKT5TE8AAH5TiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCACl9UxPAM5m7x48kjU/2Z6t/9OXvsZAzm1rzdSLzs1NX5yYsaPPOdPTg7NO09DQ0NCZngScbTb17svDPW/k31/fnSQ5MnBseF1ba3OGksz+/Ljc/qXLMq3zvDM0Szj7iCKcZqs2bsvK9VvTGBjMyd59TU1JW2tLlnVPzc3XXHLa5gdnM58pwvt0dXWlp6fnlIz9f0F8LYf7Tx7EJBkaSg73D2bl+teyauO2UzIf4HiiCO+zZcuWzJ49+xMfd1PvvqxcvzWH+499+Ma/5HD/saxcvzWbt+/7WM+/bdu2zJkzJyNHjszUqVOzYcOGjzUefBaJIpxiAwMDSZKHe95IY2DwI43RGBjMt3ve+FjzWLRoUa666qrs2bMnK1euzPz587N79+6PNSZ81ogivM8ll1ySDRs2ZPny5VmwYEFuueWWdHR0pKurKy+//PLwdr29vbnxxhszbty4jB07NnfccUeS5Mknn8zMmTNzzz33ZOzYsVm+fHnePXgka3/wvWx/7Lb0fuur2fX9b2Zg/8+Hx9r7/N9l+8O35u2/vinvPPGNNHpfHV53ZOdPs/OJu/P4n/1RLrxwfO69997hdRs3bsy1116b8847L9OmTfuVl31ff/31vPLKK1mxYkXa29szb968XHHFFXn66ac/4aMHn26iCCexdu3aLFy4MPv27csNN9wwHL7BwcHMnTs3kydPzrZt27Jjx44sXLhweL8XX3wxU6ZMya5du7Js2bJ882+eyN4Xvp8L/3RZJn7jH3POxK68u/aB4e1/a8LlmfC1v03n3asz6gtfyu5/+asMDRxNkuzd8Fg6pt+Q3136dJZ95/ksWLAgSbJjx45cf/31uf/++7N379489NBDmTdv3gnP/rZs2ZIpU6ako6NjeNm0adOyZcuWU3Lc4NNKFOEkZs2ale7u7rS0tGTJkiXZtGlTkuSll17Kzp078+CDD2bUqFFpa2vLrFmzhve7+OKLc+edd6a1tTXt7e3516e+m45rbsqICzrT1NySMdcuyNFdPxs+Wxz9e3PS0n5umppbcu4f3pgM9Kd/z/YkSVNzawbeeyeH+t7Ltv3Hcs011yRJVq1ale7u7nR3d6e5uTnXXXddpk+fnvXr13/gdRw8eDBjxow5btmYMWNy4MCBU3Lc4NPKP+/DSVx00UXDf48cOTKNRiMDAwPp7e3N5MmT09p64rdQZ2fncY/37X4nff/1WN774T/80tKhDBzYk9YxF2b/i/+cg5v/LYMH9yZpytCRX2TwcF+SZGz3Xdn3H9/Lzsf/PKvWfS5/POqBzJ07N2+99VaeeuqprFu3bnjE/v7+zJkz5wPzGT16dPr6+o5b1tfXd9yZIyCK8JF0dnbm7bffzsDAwAnD2NTUdNzjMReMT+sXb8zorg8Gq9H7avpefDrjF67MiHGT0tTUnN5vfXV4/Yjf/lzGfWVphoaO5YojWzN//vzs2bMnnZ2dWbJkSR5//PEPnW9XV1fefPPNHDhwYDiEmzZtyuLFi3/dlw6faS6fwkcwY8aMTJgwIffdd18OHTqURqORF1544Vdu/+WbbsmBjWtydPdbSZJjjUM5tPXHSZKho4fT1NySlpFjkmOD2ffjf8qxo4eH9z346o8y+Iv9aR/Rmss6xydJmpubc/PNN2fdunV57rnnMjg4mEajkZ6enmzfvv0Dz3/55ZfnyiuvzIoVK9JoNPLMM89k8+bNmTdv3id5WOBTz5kifAQtLS1Zt25d7rrrrkyaNClNTU1ZvHhxZs6cecLt//Lur+XZ//zvvLv2gQzs/3mazxmVtkuuzKips9J26dVpu/Tq7Hjs62ke0ZaOP/hKWjouGN638bOf5L0f/n2G+o8kv3NpVq9enfb29nR2dubZZ5/N0qVLs2jRorS0tGTGjBl55JFHkiS33XZbkuTRRx9NkqxevTq33nprzj///EyaNClr1qzJuHHjTvGRgk8XP/MGp8nXv/tynn9t14f+ks2JNDUlf/KF8Xn05umf/MSAYS6fwmnyF7MvS1try0fat621JbfPvuwTnhHwfqIIp8m0zvOyrHtq2kf8em+79hHNWdY9Nb8/0d0y4FTzmSKcRv9/twt3yYDfTD5ThDNg8/Z9+XbPG/nRT3enKUnjBPdTnPP5cbl99mXOEOE0EkU4g/YcPJI1r2zP1ncOpK/Rn3PbRmTqhI7Mv3pixo4+50xPD846oggAxRdtAKCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAEUUAaCIIgAUUQSAIooAUEQRAIooAkARRQAooggARRQBoIgiABRRBIAiigBQRBEAiigCQBFFACiiCABFFAGgiCIAFFEEgCKKAFBEEQCKKAJAEUUAKKIIAOV/AQEQQeMf7SiyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:['increase.0']\n",
      "Edges:[('increase.0', 'increase.0')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:['increase.1']\n",
      "Edges:[('increase.1', 'increase.1')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:['glaze.0', 'take.0']\n",
      "Edges:[('glaze.0', 'take.0'), ('take.0', 'glaze.0')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:['glaze.1']\n",
      "Edges:[('glaze.1', 'glaze.1')]\n"
     ]
    }
   ],
   "source": [
    "#### Build weighted directed graphs for transitions.\n",
    "adjacency_matrix_list = build_and_save_transition_graphs(classes, domain_name, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get Transition Sets from LOCM2\n",
    "\n",
    "Algorithm: LOCM2\n",
    "Input : \n",
    "- T_all = set of observed transitions for a sort/class\n",
    "- H : Set of holes - each hole is a set of two transitions.\n",
    "- P : Set of pairs <t1,t2> i.e. consecutive transitions.\n",
    "- E : Set of example sequences of actions.\n",
    "Output:\n",
    "- S : Set of transition sets.\n",
    "#### Finding holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix_with_holes(adjacency_matrix_list):\n",
    "    adjacency_matrix_list_with_holes = []\n",
    "    for index,adjacency_matrix in enumerate(adjacency_matrix_list):\n",
    "        # print(\"\\n ROWS ===========\")\n",
    "        df = adjacency_matrix.copy()\n",
    "        df1 = adjacency_matrix.copy()\n",
    "\n",
    "        # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "        for i in range(df.shape[0] - 1):\n",
    "            for j in range(i+1, df.shape[0]):\n",
    "                idx1, idx2 = i, j\n",
    "                row1, row2 = df.iloc[idx1,:], df.iloc[idx2, :] #we have now all pairs of rows\n",
    "\n",
    "                common_values_flag = False #for each two rows we have a common_values_flag\n",
    "\n",
    "                # if there is a common value between two rows, turn common value flag to true\n",
    "                for col in range(row1.shape[0]):\n",
    "                    if row1.iloc[col] > 0 and row2.iloc[col] > 0:\n",
    "                        common_values_flag = True\n",
    "                        break\n",
    "\n",
    "                # now if two rows have common values, we need to check for holes.\n",
    "                if common_values_flag:\n",
    "                    for col in range(row1.shape[0]):\n",
    "                        if row1.iloc[col] > 0 and row2.iloc[col] == 0:\n",
    "                            df1.iloc[idx2,col] = 'hole'\n",
    "                        elif row1.iloc[col] == 0 and row2.iloc[col] > 0:\n",
    "                            df1.iloc[idx1, col] = 'hole'\n",
    "\n",
    "        adjacency_matrix_list_with_holes.append(df1)\n",
    "    return adjacency_matrix_list_with_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========planing==========\n",
      "|      |   do.0 |\n",
      "|------|--------|\n",
      "| do.0 |      1 |\n",
      "\n",
      "===== HOLES: planing==========\n",
      "\\begin{tabular}{lr}\n",
      "\\hline\n",
      "      &   do.0 \\\\\n",
      "\\hline\n",
      " do.0 &      1 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "==========colour==========\n",
      "|       |   use.0 |\n",
      "|-------|---------|\n",
      "| use.0 |       1 |\n",
      "\n",
      "===== HOLES: colour==========\n",
      "\\begin{tabular}{lr}\n",
      "\\hline\n",
      "       &   use.0 \\\\\n",
      "\\hline\n",
      " use.0 &       1 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "==========cost==========\n",
      "|            |   increase.0 |\n",
      "|------------|--------------|\n",
      "| increase.0 |            3 |\n",
      "\n",
      "===== HOLES: cost==========\n",
      "\\begin{tabular}{lr}\n",
      "\\hline\n",
      "            &   increase.0 \\\\\n",
      "\\hline\n",
      " increase.0 &            3 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "==========plane==========\n",
      "|            |   increase.1 |\n",
      "|------------|--------------|\n",
      "| increase.1 |            2 |\n",
      "\n",
      "===== HOLES: plane==========\n",
      "\\begin{tabular}{lr}\n",
      "\\hline\n",
      "            &   increase.1 \\\\\n",
      "\\hline\n",
      " increase.1 &            2 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "==========piece==========\n",
      "|         |   glaze.0 |   take.0 |\n",
      "|---------|-----------|----------|\n",
      "| glaze.0 |         0 |        1 |\n",
      "| take.0  |         1 |        0 |\n",
      "\n",
      "===== HOLES: piece==========\n",
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      "         &   glaze.0 &   take.0 \\\\\n",
      "\\hline\n",
      " glaze.0 &         0 &        1 \\\\\n",
      " take.0  &         1 &        0 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\n",
      "==========wood==========\n",
      "|         |   glaze.1 |\n",
      "|---------|-----------|\n",
      "| glaze.1 |         1 |\n",
      "\n",
      "===== HOLES: wood==========\n",
      "\\begin{tabular}{lr}\n",
      "\\hline\n",
      "         &   glaze.1 \\\\\n",
      "\\hline\n",
      " glaze.1 &         1 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix_list_with_holes = get_adjacency_matrix_with_holes(adjacency_matrix_list)\n",
    "\n",
    "### Printing FSM matrices with and without holes\n",
    "for index,adjacency_matrix in enumerate(adjacency_matrix_list):\n",
    "    print(\"\\n==========\" + class_names[index] + \"==========\")\n",
    "    # print(adjacency_matrix)\n",
    "    print(tabulate(adjacency_matrix, headers='keys', tablefmt='github'))\n",
    "\n",
    "    print(\"\\n===== HOLES: \" + class_names[index] + \"==========\")\n",
    "    print(tabulate(adjacency_matrix_list_with_holes[index], headers='keys', tablefmt='latex'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planing:\n",
      "colour:\n",
      "cost:\n",
      "plane:\n",
      "piece:\n",
      "wood:\n"
     ]
    }
   ],
   "source": [
    "# Create list of set of holes per class (H)\n",
    "holes_per_class = []\n",
    "\n",
    "for index,df in enumerate(adjacency_matrix_list_with_holes):\n",
    "    holes = set()\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[1]):\n",
    "            if df.iloc[i,j] == 'hole':\n",
    "                holes.add(frozenset({df.index[i] , df.columns[j]}))\n",
    "    holes_per_class.append(holes)\n",
    "for i, hole in enumerate(holes_per_class):\n",
    "    print(class_names[i]+\":\")\n",
    "    for h in hole:\n",
    "        print(list(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planing:['do.0']\n",
      "colour:['use.0']\n",
      "cost:['increase.0']\n",
      "plane:['increase.1']\n",
      "piece:['glaze.0' 'take.0']\n",
      "wood:['glaze.1']\n"
     ]
    }
   ],
   "source": [
    "# List of transitions per class (T_all). It is just a set of transitions that occur for a class.\n",
    "transitions_per_class = []\n",
    "for index, df in enumerate(adjacency_matrix_list_with_holes):\n",
    "    transitions_per_class.append(df.columns.values)\n",
    "for i, transition in enumerate(transitions_per_class):\n",
    "    print('{}:{}'.format(class_names[i], transition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consecutive_transitions_per_class(adjacency_matrix_list_with_holes):\n",
    "    consecutive_transitions_per_class = []\n",
    "    for index, df in enumerate(adjacency_matrix_list_with_holes):\n",
    "        consecutive_transitions = set()  # for a class\n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(df.shape[1]):\n",
    "                if df.iloc[i, j] != 'hole':\n",
    "                    if df.iloc[i, j] > 0:\n",
    "                        # print(\"(\" + df.index[i] + \",\" + df.columns[j] + \")\")\n",
    "                        consecutive_transitions.add((df.index[i], df.columns[j]))\n",
    "        consecutive_transitions_per_class.append(consecutive_transitions)\n",
    "    return consecutive_transitions_per_class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planing:\n",
      "('do.0', 'do.0')\n",
      "\n",
      "colour:\n",
      "('use.0', 'use.0')\n",
      "\n",
      "cost:\n",
      "('increase.0', 'increase.0')\n",
      "\n",
      "plane:\n",
      "('increase.1', 'increase.1')\n",
      "\n",
      "piece:\n",
      "('take.0', 'glaze.0')\n",
      "('glaze.0', 'take.0')\n",
      "\n",
      "wood:\n",
      "('glaze.1', 'glaze.1')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Create list of consecutive transitions per class (P). If value is not null, ordered pair i,j would be consecutive transitions per class\n",
    "consecutive_transitions_per_class = get_consecutive_transitions_per_class(adjacency_matrix_list_with_holes)\n",
    "for i, transition in enumerate(consecutive_transitions_per_class):\n",
    "    print(class_names[i]+\":\")\n",
    "    for x in list(transition):\n",
    "        print(x)\n",
    "#     print('{}:{}'.format(class_names[i], transition))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Getting transitions sets for each class using LOCM2 ######\n",
      "*********************************************************************************\n",
      "\n",
      "planing\n",
      "Number of holes: 0\n",
      "set()\n",
      "Transitions of the class (T_all):\n",
      "['do.0']\n",
      "Number of values: 1\n",
      "Transition Pairs per class (P):\n",
      "{('do.0', 'do.0')}\n",
      "\n",
      "\n",
      "===========CHECKING CANDIDATE SETS OF CLASS planing FOR WELL_FORMEDNESS AND VALIDITY========\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n",
      "\n",
      "Final transition set list\n",
      "planing\n",
      "[{'do.0'}]\n",
      "*********************************************************************************\n",
      "\n",
      "colour\n",
      "Number of holes: 0\n",
      "set()\n",
      "Transitions of the class (T_all):\n",
      "['use.0']\n",
      "Number of values: 1\n",
      "Transition Pairs per class (P):\n",
      "{('use.0', 'use.0')}\n",
      "\n",
      "\n",
      "===========CHECKING CANDIDATE SETS OF CLASS colour FOR WELL_FORMEDNESS AND VALIDITY========\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n",
      "\n",
      "Final transition set list\n",
      "colour\n",
      "[{'use.0'}]\n",
      "*********************************************************************************\n",
      "\n",
      "cost\n",
      "Number of holes: 0\n",
      "set()\n",
      "Transitions of the class (T_all):\n",
      "['increase.0']\n",
      "Number of values: 1\n",
      "Transition Pairs per class (P):\n",
      "{('increase.0', 'increase.0')}\n",
      "\n",
      "\n",
      "===========CHECKING CANDIDATE SETS OF CLASS cost FOR WELL_FORMEDNESS AND VALIDITY========\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n",
      "\n",
      "Final transition set list\n",
      "cost\n",
      "[{'increase.0'}]\n",
      "*********************************************************************************\n",
      "\n",
      "plane\n",
      "Number of holes: 0\n",
      "set()\n",
      "Transitions of the class (T_all):\n",
      "['increase.1']\n",
      "Number of values: 1\n",
      "Transition Pairs per class (P):\n",
      "{('increase.1', 'increase.1')}\n",
      "\n",
      "\n",
      "===========CHECKING CANDIDATE SETS OF CLASS plane FOR WELL_FORMEDNESS AND VALIDITY========\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n",
      "\n",
      "Final transition set list\n",
      "plane\n",
      "[{'increase.1'}]\n",
      "*********************************************************************************\n",
      "\n",
      "piece\n",
      "Number of holes: 0\n",
      "set()\n",
      "Transitions of the class (T_all):\n",
      "['glaze.0' 'take.0']\n",
      "Number of values: 2\n",
      "Transition Pairs per class (P):\n",
      "{('take.0', 'glaze.0'), ('glaze.0', 'take.0')}\n",
      "\n",
      "\n",
      "===========CHECKING CANDIDATE SETS OF CLASS piece FOR WELL_FORMEDNESS AND VALIDITY========\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n",
      "\n",
      "Final transition set list\n",
      "piece\n",
      "[{'glaze.0', 'take.0'}]\n",
      "*********************************************************************************\n",
      "\n",
      "wood\n",
      "Number of holes: 0\n",
      "set()\n",
      "Transitions of the class (T_all):\n",
      "['glaze.1']\n",
      "Number of values: 1\n",
      "Transition Pairs per class (P):\n",
      "{('glaze.1', 'glaze.1')}\n",
      "\n",
      "\n",
      "===========CHECKING CANDIDATE SETS OF CLASS wood FOR WELL_FORMEDNESS AND VALIDITY========\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n",
      "\n",
      "Final transition set list\n",
      "wood\n",
      "[{'glaze.1'}]\n"
     ]
    }
   ],
   "source": [
    "def check_well_formed(subset_df):\n",
    "    # got the adjacency matrix subset\n",
    "    df = subset_df.copy()\n",
    "\n",
    "    # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "    for i in range(df.shape[0] - 1):\n",
    "        for j in range(i + 1, df.shape[0]):\n",
    "            idx1, idx2 = i, j\n",
    "            row1, row2 = df.iloc[idx1, :], df.iloc[idx2, :]  # we have now all pairs of rows\n",
    "\n",
    "            common_values_flag = False  # for each two rows we have a common_values_flag\n",
    "\n",
    "            # if there is a common value between two rows, turn common value flag to true\n",
    "            for col in range(row1.shape[0]):\n",
    "                if row1.iloc[col] > 0 and row2.iloc[col] > 0:\n",
    "                    common_values_flag = True\n",
    "                    break\n",
    "\n",
    "            # now if two rows have common values, we need to check for holes.\n",
    "            if common_values_flag:\n",
    "                for col in range(row1.shape[0]):\n",
    "                    if row1.iloc[col] > 0 and row2.iloc[col] == 0:\n",
    "                        return False\n",
    "                    elif row1.iloc[col] == 0 and row2.iloc[col] > 0:\n",
    "                        return False\n",
    "    return True\n",
    "\n",
    "def check_valid(subset_df,consecutive_transitions_per_class):\n",
    "\n",
    "    # Reasoning: If we check against all consecutive transitions of all classes, we essentially checked against all example sequences.\n",
    "    # You check the candidate set which is well-formed (subset df against all consecutive transitions)\n",
    "\n",
    "    # got the adjacency matrix subset\n",
    "    df = subset_df.copy()\n",
    "\n",
    "    # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[0]):\n",
    "            if df.iloc[i,j] > 0:\n",
    "                valid_val_flag = False\n",
    "                ordered_pair = (df.index[i], df.columns[j])\n",
    "                for ct_list in consecutive_transitions_per_class:\n",
    "                    for ct in ct_list:\n",
    "                        if ordered_pair == ct:\n",
    "                            valid_val_flag=True\n",
    "                # if after all iteration ordered pair is not found, mark the subset as invalid.\n",
    "                if not valid_val_flag:\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def locm2_get_transition_sets_per_class(holes_per_class, transitions_per_class, consecutive_transitions_per_class):\n",
    "    \"\"\" LOCM 2 Algorithm\"\"\"\n",
    "    transition_sets_per_class = []\n",
    "\n",
    "    # for each hole in a class of objects.\n",
    "    for index, holes in enumerate(holes_per_class):\n",
    "        class_name = class_names[index]\n",
    "        print(\"*********************************************************************************\")\n",
    "        print()\n",
    "        print(class_name)\n",
    "        print(\"Number of holes: \"+ str(len(holes))) # if number of holes == 0 then class is well-formed i.e. shouldn't change.\n",
    "        print(holes)\n",
    "        print(\"Transitions of the class (T_all):\")\n",
    "        print(transitions_per_class[index])\n",
    "        print(\"Number of values: \" + str(len(consecutive_transitions_per_class[index])))\n",
    "        print(\"Transition Pairs per class (P):\")\n",
    "        print(consecutive_transitions_per_class[index])\n",
    "        print()\n",
    "\n",
    "        transition_set_list = [] #transition_sets_of_a_class, # intially its empty\n",
    "        print(\"\\n===========CHECKING CANDIDATE SETS OF CLASS \" + class_name + \" FOR WELL_FORMEDNESS AND VALIDITY========\")\n",
    "        if len(holes) > 0: # if there are any holes for a class\n",
    "            for hole in holes:\n",
    "                is_hole_already_covered_flag = False\n",
    "                if len(transition_set_list)>0:\n",
    "                    for s_prime in transition_set_list:\n",
    "                        if hole.issubset(s_prime):\n",
    "                            is_hole_already_covered_flag = True\n",
    "                            break\n",
    "                # discover a set which includes hole and is well-formed and valid against test data.\n",
    "                if not is_hole_already_covered_flag: # if not covered, do BFS with sets of increasing sizes starting with s=hole\n",
    "                    s = hole.copy()\n",
    "                    candidate_sets = []\n",
    "                    for i in range(len(s)+1,len(transitions_per_class[index])): # all subsets of T_all starting from hole's len +1\n",
    "                        subsets = findsubsets(transitions_per_class[index],i)\n",
    "\n",
    "                        # append the subsets which are subset of\n",
    "                        for candidate_set in subsets:\n",
    "                            if s.issubset(candidate_set):\n",
    "                                candidate_sets.append(set(candidate_set))\n",
    "\n",
    "                        # print(\"\\n===========CHECKING CANDIDATE SETS FOR WELL_FORMEDNESS AND VALIDITY========\")\n",
    "                        for candidate_set in candidate_sets:\n",
    "                            # print(candidate_set)\n",
    "                            subset_df = adjacency_matrix_list[index].loc[list(candidate_set),list(candidate_set)]\n",
    "                            # print_table(subset_df)\n",
    "\n",
    "                            # checking for well-formedness\n",
    "                            well_formed_flag = check_well_formed(subset_df)\n",
    "                            if not well_formed_flag:\n",
    "                                # print(\"This subset is NOT well-formed\")\n",
    "                                pass\n",
    "\n",
    "                            # if well-formed validate across the data to remove inappropriate dead-ends\n",
    "                            # additional check\n",
    "                            valid_against_data_flag = False\n",
    "                            if well_formed_flag:\n",
    "                                # print_table(subset_df)\n",
    "                                # print(\"This subset is well-formed\")\n",
    "\n",
    "                                # validate against all consecutive transitions per class (P)\n",
    "                                # This checks all sequences consecutive transitions. So, it is validating against (E)\n",
    "                                valid_against_data_flag = check_valid(subset_df, consecutive_transitions_per_class)\n",
    "                                if not valid_against_data_flag:\n",
    "                                    print(\"Invalid against data\")\n",
    "\n",
    "                            if valid_against_data_flag:\n",
    "                                print(\"Adding this subset as well-formed and valid.\")\n",
    "                                print_table(subset_df)\n",
    "                                print(candidate_set)\n",
    "                                if candidate_set not in transition_set_list: # do not allow copies.\n",
    "                                    transition_set_list.append(candidate_set)\n",
    "                                break\n",
    "                        print(\"Hole that is covered now:\")\n",
    "                        print(list(s))\n",
    "                        break\n",
    "\n",
    "\n",
    "            # print(transition_set_list)\n",
    "        #step -7 : remove redundant sets\n",
    "        ts_copy = transition_set_list.copy()\n",
    "        for i in range(len(ts_copy)):\n",
    "            for j in range(len(ts_copy)):\n",
    "                if ts_copy[i] < ts_copy[j]: #if subset\n",
    "                    if ts_copy[i] in transition_set_list:\n",
    "                        transition_set_list.remove(ts_copy[i])\n",
    "                elif ts_copy[i] > ts_copy[j]:\n",
    "                    if ts_copy[j] in transition_set_list:\n",
    "                        transition_set_list.remove(ts_copy[j])\n",
    "        print(\"\\nRemoved redundancy transition set list\")\n",
    "        print(transition_set_list)\n",
    "\n",
    "        #step-8: include all-transitions machine, even if it is not well-formed.\n",
    "        transition_set_list.append(set(transitions_per_class[index]))\n",
    "        print(\"\\nFinal transition set list\")\n",
    "        print(class_name)\n",
    "        print(transition_set_list)\n",
    "\n",
    "\n",
    "        transition_sets_per_class.append(transition_set_list)\n",
    "    return transition_sets_per_class\n",
    "\n",
    "\n",
    "############    LOCM2 #################\n",
    "####    Input ready for LOCM2, Starting LOCM2 algorithm now\n",
    "####    Step 8:  selecting transition sets (TS) [Main LOCM2 Algorithm]\n",
    "print(\"######## Getting transitions sets for each class using LOCM2 ######\")\n",
    "transition_sets_per_class = locm2_get_transition_sets_per_class(holes_per_class, transitions_per_class, consecutive_transitions_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Algorithm For Induction of State Machines\n",
    "\n",
    "- Input: Action training sequence of length N\n",
    "- Output: Transition Set TS, Object states OS.\n",
    "\n",
    "We already have transition set TS per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Induction of Finite State Machines\n",
      "planing\n",
      "Number of FSMS:1\n",
      "colour\n",
      "Number of FSMS:1\n",
      "cost\n",
      "Number of FSMS:1\n",
      "plane\n",
      "Number of FSMS:1\n",
      "piece\n",
      "Number of FSMS:1\n",
      "wood\n",
      "Number of FSMS:1\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Induction of Finite State Machines\")\n",
    "state_machines_overall_list = [] # list of all state machines\n",
    "state_dict_overall = [] #list of state dict per class\n",
    "\n",
    "for index, ts in enumerate(transition_sets_per_class):\n",
    "    state_machines_per_class = [] # state machines for each class.\n",
    "    state_dict_per_class = []\n",
    "    print(class_names[index])\n",
    "    # print(ts)\n",
    "    num_fsms = len(ts)\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "\n",
    "\n",
    "    #### Add state identifiers\n",
    "    states_per_transition_set = []\n",
    "    for transition_set in ts:\n",
    "        states = set()\n",
    "        for transition in transition_set:\n",
    "            states.add(frozenset({\"start(\" + transition + \")\"}))\n",
    "            states.add(frozenset({\"end(\" + transition + \")\"}))\n",
    "        states_per_transition_set.append(states)\n",
    "\n",
    "    # print(states_per_transition_set)\n",
    "\n",
    "    #### For each pair of consecutive transitions T1, T2 in TS: Unify states end(T1) and start(T2) in set OS\n",
    "    for fsm_no, transition_set in enumerate(ts):\n",
    "        transition_df = adjacency_matrix_list[index].loc[list(transition_set), list(transition_set)] #uses transition matrix without holes\n",
    "\n",
    "        consecutive_transitions_state_machines_per_class = set()  # find consecutive transitions for a state machine in a class.\n",
    "        for i in range(transition_df.shape[0]):\n",
    "            for j in range(transition_df.shape[1]):\n",
    "                if transition_df.iloc[i, j] != 'hole':\n",
    "                    if transition_df.iloc[i, j] > 0:\n",
    "                        consecutive_transitions_state_machines_per_class.add((transition_df.index[i], transition_df.columns[j]))\n",
    "\n",
    "        # for every consecutive transition and for every state of a class, check if that state matches end(t1) or start(t2)\n",
    "        for ct in consecutive_transitions_state_machines_per_class:\n",
    "            s1, s2, s3 = -1, -1, -1\n",
    "            for s in states_per_transition_set[fsm_no]:\n",
    "                if \"end(\"+ct[0]+\")\" in s:\n",
    "                    s1 = s\n",
    "                if \"start(\"+ct[1]+\")\" in s:\n",
    "                    s2 = s\n",
    "                if s1 != -1 and s2 != - 1: #if they do, combine them.\n",
    "                    s3 = s1.union(s2) # union\n",
    "\n",
    "            if s1 != -1 and s2 != -1 and s3 != -1: #for every ct, if we have combined state, we update states_per_transition_set\n",
    "                if s1 in states_per_transition_set[fsm_no]:\n",
    "                    states_per_transition_set[fsm_no].remove(s1)\n",
    "                if s2 in states_per_transition_set[fsm_no]:\n",
    "                    states_per_transition_set[fsm_no].remove(s2)\n",
    "                states_per_transition_set[fsm_no].add(s3)\n",
    "\n",
    "        ## build a state machine now.\n",
    "        fsm_graph = nx.DiGraph()\n",
    "\n",
    "        # TODO: consider making a state dictionary for pretty print of frozen set\n",
    "        state_dict_per_class.insert(fsm_no,{})\n",
    "        for i, state in enumerate(states_per_transition_set[fsm_no]):\n",
    "            state_dict_per_class[fsm_no][\"state\"+str(i)] = state\n",
    "            fsm_graph.add_node(\"state\"+str(i))\n",
    "\n",
    "        # transition_df is defined above. Add edges from transitions.\n",
    "        # print_table(transition_df)\n",
    "        for i in range(transition_df.shape[0]):\n",
    "            for j in range(transition_df.shape[1]):\n",
    "                if transition_df.iloc[i, j] != 'hole':\n",
    "                    if transition_df.iloc[i, j] > 0:\n",
    "                        for node in fsm_graph.nodes():\n",
    "                            starting_node, ending_node = -1,-1\n",
    "                            if \"end(\"+transition_df.index[i]+\")\" in state_dict_per_class[fsm_no][node]:\n",
    "                                starting_node = node\n",
    "                            if \"start(\"+transition_df.columns[j]+\")\" in state_dict_per_class[fsm_no][node]:\n",
    "                                ending_node = node\n",
    "                            if starting_node != -1 and ending_node != -1:\n",
    "                                if fsm_graph.has_edge(starting_node, ending_node):\n",
    "                                    fsm_graph[starting_node][ending_node]['weight'] += transition_df.iloc[i, j]\n",
    "                                else:\n",
    "                                    fsm_graph.add_edge(starting_node, ending_node, weight=transition_df.iloc[i, j], name=\"\"+transition_df.index[i])\n",
    "\n",
    "        df = nx.to_pandas_adjacency(fsm_graph, nodelist=fsm_graph.nodes(), dtype=int)\n",
    "        \n",
    "        nx.write_graphml(fsm_graph, \"output/\" + domain_name + \"/\" + class_names[index] + \"_stateFSM_\" + str(fsm_no+1)+ \".graphml\")\n",
    "        state_machines_per_class.append(df)\n",
    "\n",
    "    state_machines_overall_list.append(state_machines_per_class)\n",
    "    state_dict_overall.append(state_dict_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS:planing\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        1 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'do.0'}]\n",
      "CLASS:colour\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        1 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'use.0'}]\n",
      "CLASS:cost\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        3 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'increase.0'}]\n",
      "CLASS:plane\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        2 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'increase.1'}]\n",
      "CLASS:piece\n",
      "FSM:1\n",
      "+--------+----------+----------+\n",
      "|        |   state0 |   state1 |\n",
      "|--------+----------+----------|\n",
      "| state0 |        1 |        0 |\n",
      "| state1 |        0 |        1 |\n",
      "+--------+----------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'glaze.0', 'take.0'}]\n",
      "CLASS:wood\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        1 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'glaze.1'}]\n"
     ]
    }
   ],
   "source": [
    "for index, fsms_per_class in enumerate(state_machines_overall_list):\n",
    "    class_name = class_names[index]\n",
    "    print(\"CLASS:\"+ class_name)\n",
    "    for fsm_no, fsm in enumerate(fsms_per_class):\n",
    "        print(\"FSM:\" + str(fsm_no + 1))\n",
    "        print_table(fsm)\n",
    "\n",
    "    print(\"\\nTransition set of this class:\")\n",
    "    print(transition_sets_per_class[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planing_fsm0_state0:['start(do.0)', 'end(do.0)']\n",
      "colour_fsm0_state0:['end(use.0)', 'start(use.0)']\n",
      "cost_fsm0_state0:['start(increase.0)', 'end(increase.0)']\n",
      "plane_fsm0_state0:['start(increase.1)', 'end(increase.1)']\n",
      "piece_fsm0_state0:['end(glaze.0)', 'start(take.0)']\n",
      "piece_fsm0_state1:['start(glaze.0)', 'end(take.0)']\n",
      "wood_fsm0_state0:['start(glaze.1)', 'end(glaze.1)']\n"
     ]
    }
   ],
   "source": [
    "# pretty print state dictionary.\n",
    "def print_state_dictionary(state_dict_overall):\n",
    "    for i,state_dict_per_class in enumerate(state_dict_overall):\n",
    "#         print(class_names[i])\n",
    "        for j,state_dict_per_fsm in enumerate(state_dict_per_class):\n",
    "#             print()\n",
    "            for k,v in state_dict_per_fsm.items():\n",
    "                print(class_names[i]+\"_fsm\"+str(j)+\"_\"+ k + \":\"+str(list(v)))\n",
    "#                 print(list(v))\n",
    "#                 print()\n",
    "                \n",
    "print_state_dictionary(state_dict_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Zero Analysis\n",
    "\n",
    "behavior of implicit background object, e.g., hand object in AOP freecell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Assume every action has a zeroth object, ..in our implementation we already have zeroth object ..so we literally name it as 'zero'\n",
    "\n",
    "# def read_file_zero(file_path):\n",
    "#     '''\n",
    "#     Read the input data and return list of action sequences.\n",
    "#     Each sequence is a list of action-argumentlist tuples.\n",
    "#     '''\n",
    "#     file = open(input_file_name, 'r')\n",
    "#     sequences = []\n",
    "#     for line in file:\n",
    "        \n",
    "#         actions = []\n",
    "#         arguments = []\n",
    "#         if line and not line.isspace() and len(line)>1:\n",
    "#             sequence = line.rstrip(\"\\n\\r\").lstrip(\"\\n\\r\").lower() \n",
    "#             action_defs = sequence.split(\"),\")\n",
    "\n",
    "#             for action_def in action_defs:\n",
    "#                 action = action_def.split('(')[0].strip(\")\\n\\r\").strip()\n",
    "#                 argument = action_def.split('(')[1].strip(\")\\n\\r\")\n",
    "#                 actions.append(action.strip())\n",
    "#                 argument_list = argument.split(',')\n",
    "#                 argument_list = [x.strip() for x in argument_list]\n",
    "#                 argument_list.insert(0, 'zero')\n",
    "#                 arguments.append(argument_list)\n",
    "            \n",
    "#             actarg_tuples = zip(actions,arguments)\n",
    "#             sequences.append(list(actarg_tuples))\n",
    "#     return sequences\n",
    "\n",
    "# def print_sequences(sequences):\n",
    "#     for seq in sequences:\n",
    "#         for action in seq:\n",
    "#             print(action)\n",
    "#         print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_sequences = read_file_zero(input_file_name)\n",
    "# print_sequences(zero_sequences)\n",
    "\n",
    "# transitions_zero = set() # A transition is denoted by action_name + argument_number.\n",
    "# arguments_zero = set()\n",
    "# actions_zero = set()\n",
    "\n",
    "# for seq in zero_sequences:\n",
    "#     for actarg_tuple in seq:\n",
    "#         actions_zero.add(actarg_tuple[0])\n",
    "#         for j, arg in enumerate(actarg_tuple[1]):\n",
    "#             transitions_zero.add(actarg_tuple[0]+\".\"+str(j))\n",
    "#             arguments_zero.add(arg)\n",
    "\n",
    "\n",
    "# print(\"\\nActions Zero\")\n",
    "# print(actions_zero)\n",
    "# print(\"\\nTransitions Zero\")\n",
    "# print(transitions_zero)\n",
    "# print(\"\\nArguments/Objects Zero\")\n",
    "# print(arguments_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = get_actarg_dictionary(zero_sequences)\n",
    "# for k,v in d.items():\n",
    "#         print(\"{} - {}\".format(k,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes_zero = get_classes(d) #sorts of object\n",
    "# print(\"\\nSorts/Classes\")\n",
    "# print(classes_zero)\n",
    "\n",
    "# class_names_zero = get_class_names(classes_zero)\n",
    "# print(\"\\nExtracted class names\")\n",
    "\n",
    "\n",
    "# class_names_zero[4] = 'location'\n",
    "# print(class_names_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Induction of parameterized state machines\n",
    "Create and test hypothesis for state parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "Step 5: Induction of Parameterised Finite State Machines\n",
      "CLASS:planing\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        1 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'do.0'}]\n",
      "CLASS:colour\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        1 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'use.0'}]\n",
      "CLASS:cost\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        3 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'increase.0'}]\n",
      "CLASS:plane\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        2 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'increase.1'}]\n",
      "CLASS:piece\n",
      "FSM:1\n",
      "+--------+----------+----------+\n",
      "|        |   state0 |   state1 |\n",
      "|--------+----------+----------|\n",
      "| state0 |        1 |        0 |\n",
      "| state1 |        0 |        1 |\n",
      "+--------+----------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'glaze.0', 'take.0'}]\n",
      "CLASS:wood\n",
      "FSM:1\n",
      "+--------+----------+\n",
      "|        |   state0 |\n",
      "|--------+----------|\n",
      "| state0 |        1 |\n",
      "+--------+----------+\n",
      "\n",
      "Transition set of this class:\n",
      "[{'glaze.1'}]\n"
     ]
    }
   ],
   "source": [
    "## Step 5 Input: action sequence Seq, Transition set TS, Object set Obs\n",
    "## Output: HS retained hypotheses for state parameters\n",
    "## 5.1 Form hypotheses from state machines\n",
    "print(\"*****************\")\n",
    "print(\"Step 5: Induction of Parameterised Finite State Machines\")\n",
    "HS_list = []\n",
    "for index, fsms_per_class in enumerate(state_machines_overall_list):\n",
    "    class_name = class_names[index]\n",
    "    print(\"CLASS:\"+ class_name)\n",
    "    for fsm_no, fsm in enumerate(fsms_per_class):\n",
    "        print(\"FSM:\" + str(fsm_no + 1))\n",
    "        print_table(fsm)\n",
    "\n",
    "    print(\"\\nTransition set of this class:\")\n",
    "    print(transition_sets_per_class[index])\n",
    "\n",
    "    # Hypothesis set per class.\n",
    "    HS_per_class = []\n",
    "    for fsm_no, transition_set in enumerate(transition_sets_per_class[index]):\n",
    "        transition_df = adjacency_matrix_list[index].loc[list(transition_set), list(transition_set)]\n",
    "        consecutive_transitions_state_machines_per_class = set()  # find consecutive transitions for a state machine in a class.\n",
    "        for i in range(transition_df.shape[0]):\n",
    "            for j in range(transition_df.shape[1]):\n",
    "                if transition_df.iloc[i, j] != 'hole':\n",
    "                    if transition_df.iloc[i, j] > 0:\n",
    "                        consecutive_transitions_state_machines_per_class.add((transition_df.index[i], transition_df.columns[j]))\n",
    "\n",
    "        # Step 5.1 for each pair <B.k and C.l> of consecutive transitions in transition set of a state machine.\n",
    "        # store hypothesis in Hypothesis set\n",
    "        HS = set()\n",
    "        for ct in consecutive_transitions_state_machines_per_class:\n",
    "            B = ct[0].split('.')[0] # action name of T1\n",
    "            k = int(ct[0].split('.')[1]) # argument index of T1\n",
    "\n",
    "            C = ct[1].split('.')[0] # action name of T2\n",
    "            l = int(ct[1].split('.')[1]) # argument index of T2\n",
    "\n",
    "            # When both actions B and C contain another argument of the same sort G' in position k' and l' respectively, we hypothesise that there may be a relation between sorts G and G'.\n",
    "            for seq in sequences:\n",
    "                for actarg_tuple in seq:\n",
    "                    arglist1 = []\n",
    "                    arglist2 = []\n",
    "                    if actarg_tuple[0] == B: #if action name is same as B\n",
    "                        arglist1 = actarg_tuple[1].copy()\n",
    "                        arglist1.remove(actarg_tuple[1][k]) # remove k from arglist\n",
    "                        for actarg_tuple_prime in seq: #loop through seq again.\n",
    "                            if actarg_tuple_prime[0] == C:\n",
    "                                arglist2 = actarg_tuple_prime[1].copy()\n",
    "                                arglist2.remove(actarg_tuple_prime[1][l]) # remove l from arglist\n",
    "\n",
    "                        # for arg lists of actions B and C, if class is same add a hypothesis set.\n",
    "                        for i in range(len(arglist1)):\n",
    "                            for j in range(len(arglist2)):\n",
    "                                class1 = get_class_index(arglist1[i], classes)\n",
    "                                class2 = get_class_index(arglist2[j], classes)\n",
    "                                if class1 == class2:\n",
    "                                    HS.add((frozenset({\"end(\"+B+\".\"+ str(k)+\")\", \"start(\"+C+\".\"+str(l)+\")\"}),B,k,i,C,l,j,index,class1))\n",
    "\n",
    "        ####### Step 5.2 Test Hypothesis against example sequences!!\n",
    "        # Check hypothesis against sequences.\n",
    "        ## It performs an inductive process such that the hypotheses can be either refuted or retained according to the example sequence, but it can never be definitely confirmed.\n",
    "        ## Requires more data than usual.\n",
    "        HS_copy = HS.copy()\n",
    "        for hs in HS:\n",
    "            # for every consecutive transision for a state machine per class.\n",
    "            for ct in consecutive_transitions_state_machines_per_class:\n",
    "                A_p = ct[0].split('.')[0]\n",
    "                m = int(ct[0].split('.')[1])\n",
    "\n",
    "                A_q = ct[1].split('.')[0]\n",
    "                n = int(ct[1].split('.')[1])\n",
    "\n",
    "                if A_p == hs[1] and m == hs[2] and A_q == hs[4] and n == hs[5]:\n",
    "                    k_prime = hs[3]\n",
    "                    l_prime = hs[6]\n",
    "                    for seq in sequences:\n",
    "                        for actarg_tuple in seq:\n",
    "                            arglist1 = []\n",
    "                            arglist2 = []\n",
    "                            if actarg_tuple[0] == A_p:\n",
    "                                arglist1 = actarg_tuple[1].copy()\n",
    "                                arglist1.remove(actarg_tuple[1][m])  # remove k from arglist\n",
    "                                for actarg_tuple_prime in seq:\n",
    "                                    if actarg_tuple_prime[0] == A_q:\n",
    "                                        arglist2 = actarg_tuple_prime[1].copy()\n",
    "                                        arglist2.remove(actarg_tuple_prime[1][n])  # remove l from arglist\n",
    "\n",
    "#                                 class1, class2 = -1,-1\n",
    "#                                 if k_prime < len(arglist1) and l_prime < len(arglist2):\n",
    "#                                     class1 = get_class_index(arglist1[k_prime], classes)\n",
    "#                                     class2 = get_class_index(arglist2[l_prime], classes)\n",
    "\n",
    "#                                 # Refute the hypothesis if classes are not same at the location specified by hypothesis.\n",
    "#                                 if class1 != -1 and class2!=-1 and class1 != class2:\n",
    "#                                     if hs in HS_copy:\n",
    "#                                         HS_copy.remove(hs)\n",
    "                                object1, object2 = None, None\n",
    "                                if k_prime < len(arglist1) and l_prime < len(arglist2):\n",
    "                                    object1 = arglist1[k_prime]\n",
    "                                    object2 = arglist2[l_prime]\n",
    "                                \n",
    "                                if object1 != None and object2 !=None and object1 !=object2:\n",
    "                                    if hs in HS_copy:\n",
    "                                        HS_copy.remove(hs)\n",
    "                        \n",
    "                                 \n",
    "\n",
    "\n",
    "\n",
    "        HS_per_class.append(HS_copy)\n",
    "    HS_list.append(HS_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** HYPOTHESIS SET*********\n",
      "(frozenset({'start(increase.1)', 'end(increase.1)'}), 'increase', 1, 0, 'increase', 1, 0, 3, 2)\n",
      "(frozenset({'start(glaze.1)', 'end(glaze.1)'}), 'glaze', 1, 0, 'glaze', 1, 0, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "# printing hypothesis\n",
    "print(\"\\n****** HYPOTHESIS SET*********\")\n",
    "for HS_per_class in HS_list:\n",
    "    for HS_per_fsm in HS_per_class:\n",
    "        for h in HS_per_fsm:\n",
    "            print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Creation and merging of state parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: creating and merging state params\n",
      "planing\n",
      "\n",
      "colour\n",
      "\n",
      "cost\n",
      "\n",
      "plane\n",
      "((frozenset({'start(increase.1)', 'end(increase.1)'}), 'increase', 1, 0, 'increase', 1, 0, 3, 2), 'v0')\n",
      "\n",
      "piece\n",
      "\n",
      "wood\n",
      "((frozenset({'start(glaze.1)', 'end(glaze.1)'}), 'glaze', 1, 0, 'glaze', 1, 0, 5, 4), 'v0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 6: creating and merging state params\")\n",
    "param_bindings_list_overall = []\n",
    "for classindex, HS_per_class in enumerate(HS_list):\n",
    "    param_bind_per_class = []\n",
    "    for HS_per_fsm in HS_per_class:\n",
    "        param_binding_list = []\n",
    "        for index,h in enumerate(HS_per_fsm):\n",
    "            param_binding_list.append((h,\"v\"+str(index)))\n",
    "\n",
    "        for i in range(len(param_binding_list)-1):\n",
    "            for j in range(i+1, len(param_binding_list)):\n",
    "                h_1 = param_binding_list[i][0]\n",
    "                h_2 = param_binding_list[j][0]\n",
    "\n",
    "                if ((h_1[0] == h_2[0] and h_1[1] == h_2[1] and h_1[2] == h_2[2] and h_1[3] == h_2[3]) or (h_1[0] == h_2[0] and h_1[4] == h_2[4] and h_1[5] == h_2[5] and h_1[6] == h_2[6])):\n",
    "                    new_tuple = (param_binding_list[j][0], param_binding_list[i][1])\n",
    "                    param_binding_list.remove((param_binding_list[j][0], param_binding_list[j][1]))\n",
    "                    param_binding_list.insert(j,new_tuple)\n",
    "        param_bind_per_class.append(param_binding_list)\n",
    "        print(class_names[classindex])\n",
    "        for pb in param_binding_list:\n",
    "            print(pb)\n",
    "        print()\n",
    "    param_bindings_list_overall.append(param_bind_per_class)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Remove Parameter Flaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planing\n",
      "colour\n",
      "cost\n",
      "plane\n",
      "piece\n",
      "wood\n"
     ]
    }
   ],
   "source": [
    "########### Step 5: Removing parameter flaws\n",
    "# A parameter P associated with an FSM state S is said to be flawed if there exists a transition into S, which does not supply P with a value.\n",
    "# This may occur when there exists a transition B.k where end(B.k)=S, but there exists no h containing end(B.k)\n",
    "\n",
    "para_bind_overall_fault_removed = []\n",
    "for class_index, para_bind_per_class in enumerate(param_bindings_list_overall):\n",
    "    print(class_names[class_index])\n",
    "    para_bind_per_class_fault_removed = []\n",
    "\n",
    "    # print(state_machines_overall_list[class_index][fsm_index].index.values)\n",
    "    for fsm_index, transition_set in enumerate(transition_sets_per_class[class_index]):\n",
    "        transition_df = adjacency_matrix_list[class_index].loc[list(transition_set), list(transition_set)]\n",
    "        consecutive_transitions_state_machines_per_class = set()  # find consecutive transitions for a state machine in a class.\n",
    "        for i in range(transition_df.shape[0]):\n",
    "            for j in range(transition_df.shape[1]):\n",
    "                if transition_df.iloc[i, j] != 'hole':\n",
    "                    if transition_df.iloc[i, j] > 0:\n",
    "                        consecutive_transitions_state_machines_per_class.add(\n",
    "                            (transition_df.index[i], transition_df.columns[j]))\n",
    "\n",
    "        # initialize h_exists with false\n",
    "        h_exists = []\n",
    "        for param_index, param_bind in enumerate(para_bind_per_class[fsm_index]):\n",
    "            h_exists.append(False)\n",
    "\n",
    "        for ct in consecutive_transitions_state_machines_per_class:\n",
    "            for state in state_machines_overall_list[class_index][fsm_index].index.values:\n",
    "                if {\"end(\"+ ct[0] + \")\"} <= state_dict_overall[class_index][fsm_index][state]:\n",
    "                    current_state = state_dict_overall[class_index][fsm_index][state]\n",
    "\n",
    "                    # for every parameter binding which contains subset of current_state, if B and k are there, hypothesis exists\n",
    "                    for param_index,param_bind in enumerate(para_bind_per_class[fsm_index]):\n",
    "                        if param_bind[0][0] <= current_state: #subset of current_state of FSM\n",
    "                            # print(param_bind[0][1])\n",
    "                            # print(param_bind[0][2])\n",
    "                            # print(ct[0].split('.')[0])\n",
    "                            # print(ct[0].split('.')[1])\n",
    "                            # print()\n",
    "                            if param_bind[0][1] == ct[0].split('.')[0]:\n",
    "                                if param_bind[0][2] == int(ct[0].split('.')[1]): #TODO: Do we need to check other things here\n",
    "                                    h_exists[param_index] = True\n",
    "\n",
    "        param_bind_per_fsm_copy = para_bind_per_class[fsm_index].copy()\n",
    "        for param_index, param_bind in enumerate(para_bind_per_class[fsm_index]):\n",
    "            # if h_exists[param_index]:\n",
    "            #     print(param_bind[1])\n",
    "            if not h_exists[param_index]:\n",
    "                param_bind_per_fsm_copy.remove(param_bind)\n",
    "\n",
    "        para_bind_per_class_fault_removed.append(param_bind_per_fsm_copy)\n",
    "    para_bind_overall_fault_removed.append(para_bind_per_class_fault_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault Removed Parameter Bindings\n",
      "planing\n",
      "Fsm_no:0\n",
      "\n",
      "colour\n",
      "Fsm_no:0\n",
      "\n",
      "cost\n",
      "Fsm_no:0\n",
      "\n",
      "plane\n",
      "Fsm_no:0\n",
      "((frozenset({'start(increase.1)', 'end(increase.1)'}), 'increase', 1, 0, 'increase', 1, 0, 3, 2), 'v0')\n",
      "\n",
      "piece\n",
      "Fsm_no:0\n",
      "\n",
      "wood\n",
      "Fsm_no:0\n",
      "((frozenset({'start(glaze.1)', 'end(glaze.1)'}), 'glaze', 1, 0, 'glaze', 1, 0, 5, 4), 'v0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fault Removed Parameter Bindings\")\n",
    "for class_index, para_bind_per_class in enumerate(para_bind_overall_fault_removed):\n",
    "    print(class_names[class_index])\n",
    "    for fsm_no, para_bind_per_fsm in enumerate(para_bind_per_class):\n",
    "        print(\"Fsm_no:\" + str(fsm_no))\n",
    "        for p in para_bind_per_fsm:\n",
    "            print(p)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input 3:\n",
    "One can input static schema details here as well as edit the final state machines\n",
    "\n",
    "\n",
    "Step 8: Static Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9:  Formation of PDDL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict_overall[0][0][state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;********************Learned PDDL domain******************\n",
      "(define\t(domain woodworking)\n",
      "\t(:requirements :typing)\n",
      "\t(:types planing colour cost plane piece wood)\n",
      "\t(:predicates\n",
      "\t\t(planing_fsm0_state0)\n",
      "\t\t(colour_fsm0_state0)\n",
      "\t\t(cost_fsm0_state0)\n",
      "\t\t(plane_fsm0_state0 ?v0 - cost)\n",
      "\t\t(piece_fsm0_state0)\n",
      "\t\t(piece_fsm0_state1)\n",
      "\t\t(wood_fsm0_state0 ?v0 - piece)\n",
      ")\n",
      "\t(:action\ttake\n",
      "\t:parameters\t(?piece - piece )\n",
      "\t:precondition\t(and\n",
      "\t\t\t\t(piece_fsm0_state0)\n",
      "\t\t\t\t(piece_fsm0_state1)\n",
      "\t)\n",
      "\t:effect\t(and\n",
      "\t\t\t\t(piece_fsm0_state0)\n",
      "\t\t\t\t(piece_fsm0_state1)\n",
      "\t))\n",
      "\n",
      "\t(:action\tglaze\n",
      "\t:parameters\t(?piece - piece ?wood - wood )\n",
      "\t:precondition\t(and\n",
      "\t\t\t\t(piece_fsm0_state0)\n",
      "\t\t\t\t(piece_fsm0_state1)\n",
      "\t\t\t\t(wood_fsm0_state0 ?v0 - piece)\n",
      "\t)\n",
      "\t:effect\t(and\n",
      "\t\t\t\t(piece_fsm0_state0)\n",
      "\t\t\t\t(piece_fsm0_state1)\n",
      "\t\t\t\t(wood_fsm0_state0 ?v0 - piece)\n",
      "\t))\n",
      "\n",
      "\t(:action\tdo\n",
      "\t:parameters\t(?planing - planing )\n",
      "\t:precondition\t(and\n",
      "\t\t\t\t(planing_fsm0_state0)\n",
      "\t)\n",
      "\t:effect\t(and\n",
      "\t\t\t\t(planing_fsm0_state0)\n",
      "\t))\n",
      "\n",
      "\t(:action\tincrease\n",
      "\t:parameters\t(?cost - cost ?plane - plane )\n",
      "\t:precondition\t(and\n",
      "\t\t\t\t(cost_fsm0_state0)\n",
      "\t\t\t\t(plane_fsm0_state0 ?v0 - cost)\n",
      "\t)\n",
      "\t:effect\t(and\n",
      "\t\t\t\t(cost_fsm0_state0)\n",
      "\t\t\t\t(plane_fsm0_state0 ?v0 - cost)\n",
      "\t))\n",
      "\n",
      "\t(:action\tuse\n",
      "\t:parameters\t(?colour - colour )\n",
      "\t:precondition\t(and\n",
      "\t\t\t\t(colour_fsm0_state0)\n",
      "\t)\n",
      "\t:effect\t(and\n",
      "\t\t\t\t(colour_fsm0_state0)\n",
      "\t))\n",
      "\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get action schema\n",
    "print(\";;********************Learned PDDL domain******************\")\n",
    "output_file = \"output/\"+ domain_name + \"/\" +  domain_name + \".pddl\"\n",
    "write_file = open(output_file, 'w')\n",
    "write_line = \"(define\"\n",
    "write_line += \"\\t(domain \"+ domain_name+\")\\n\"\n",
    "write_line += \"\\t(:requirements :typing)\\n\"\n",
    "write_line += \"\\t(:types\"\n",
    "for class_name in class_names:\n",
    "    write_line += \" \" + class_name\n",
    "write_line += \")\\n\"\n",
    "write_line += \"\\t(:predicates\\n\"\n",
    "\n",
    "predicates = []\n",
    "for class_index, para_bind_per_class in enumerate(para_bind_overall_fault_removed):\n",
    "    for fsm_no, para_bind_per_fsm in enumerate(para_bind_per_class):\n",
    "        for state_index, state in enumerate(state_machines_overall_list[class_index][fsm_no]):\n",
    "            predicate = \"\"\n",
    "            write_line += \"\\t\\t(\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_state\" + str(state_index)\n",
    "            predicate += \"\\t\\t(\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_state\" + str(state_index)\n",
    "            for para_bind in para_bind_per_fsm:\n",
    "                if para_bind[0][0] <= state_dict_overall[class_index][fsm_no][state]:\n",
    "                    write_line += \" ?\"+para_bind[1] + \" - \" + str(class_names[para_bind[0][8]])\n",
    "                    predicate += \" ?\"+para_bind[1] + \" - \" + str(class_names[para_bind[0][8]])\n",
    "            write_line += \")\\n\"\n",
    "            predicate += \")\"\n",
    "            predicates.append(predicate)\n",
    "write_line += \")\\n\"\n",
    "            \n",
    "for action_index, action in enumerate(actions):\n",
    "    write_line += \"\\t(:action\"\n",
    "    write_line += \"\\t\" + action + \"\\n\"\n",
    "    write_line += \"\\t:parameters\"\n",
    "    write_line += \"\\t(\"\n",
    "    arg_already_written_flag = False\n",
    "    params_per_action = []\n",
    "    args_per_action = []\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            if not arg_already_written_flag:\n",
    "                if actarg_tuple[0] == action:\n",
    "                    arglist = []\n",
    "                    for arg in actarg_tuple[1]:\n",
    "                        write_line += \"?\"+arg + \" - \" + class_names[get_class_index(arg,classes)] + \" \"\n",
    "                        arglist.append(arg)\n",
    "                    args_per_action.append(arglist)\n",
    "                    params_per_action.append(actarg_tuple[1])\n",
    "                    arg_already_written_flag = True\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "\n",
    "    # need to use finite STATE machines to get preconditions and effects.\n",
    "    # Start-state = precondition. End state= Effect\n",
    "    preconditions = []\n",
    "    effects = []\n",
    "    for arglist in params_per_action:\n",
    "        for arg in arglist:\n",
    "            current_class_index = get_class_index(arg, classes)\n",
    "            for fsm_no, fsm in enumerate(state_machines_overall_list[current_class_index]):\n",
    "                # print_table(fsm)\n",
    "                df = fsm\n",
    "\n",
    "                for i in range(df.shape[0]):\n",
    "                    for j in range(df.shape[1]):\n",
    "                        if df.iloc[i, j] > 0:\n",
    "                            # print(\"(\" + df.index[i] + \",\" + df.columns[j] + \")\")\n",
    "                            start_state = state_dict_overall[current_class_index][fsm_no][df.index[i]]\n",
    "                            end_state = state_dict_overall[current_class_index][fsm_no][df.columns[j]]\n",
    "\n",
    "                            start_state_index, end_state_index = -1, -1\n",
    "                            for k,v in state_dict_overall[current_class_index][fsm_no].items():\n",
    "                                if v == start_state:\n",
    "                                    start_state_index = k\n",
    "                                if v == end_state:\n",
    "                                    end_state_index = k\n",
    "\n",
    "                            for predicate in predicates:\n",
    "                                pred = predicate.split()[0].lstrip('(').rstrip(')')\n",
    "                                if pred == class_names[current_class_index]+\"_fsm\"+str(fsm_no)+\"_\"+str(start_state_index):\n",
    "\n",
    "                                    if predicate not in preconditions:\n",
    "                                        preconditions.append(predicate)\n",
    "                                if pred == class_names[current_class_index]+\"_fsm\"+str(fsm_no)+\"_\"+str(end_state_index):\n",
    "                                    if predicate not in effects:\n",
    "                                        effects.append(predicate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     print(preconditions)\n",
    "#     print(effects)\n",
    "    write_line += \"\\t:precondition\"\n",
    "    write_line += \"\\t(and\\n\"\n",
    "    for precondition in preconditions:\n",
    "        # precondition = precondition.replace(?)\n",
    "        write_line += \"\\t\\t\"+precondition+\"\\n\"\n",
    "    write_line += \"\\t)\\n\"\n",
    "    write_line += \"\\t:effect\"\n",
    "    write_line += \"\\t(and\\n\"\n",
    "    for effect in effects:\n",
    "        write_line += \"\\t\\t\" + effect + \"\\n\"\n",
    "    write_line += \"\\t)\"\n",
    "\n",
    "    write_line += \")\\n\\n\"\n",
    "\n",
    "write_line += \")\\n\" #domain ending bracket\n",
    "\n",
    "\n",
    "print(write_line)\n",
    "\n",
    "write_file.write(write_line)\n",
    "write_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planing_fsm0_state0:['start(do.0)', 'end(do.0)']\n",
      "colour_fsm0_state0:['end(use.0)', 'start(use.0)']\n",
      "cost_fsm0_state0:['start(increase.0)', 'end(increase.0)']\n",
      "plane_fsm0_state0:['start(increase.1)', 'end(increase.1)']\n",
      "piece_fsm0_state0:['end(glaze.0)', 'start(take.0)']\n",
      "piece_fsm0_state1:['start(glaze.0)', 'end(take.0)']\n",
      "wood_fsm0_state0:['start(glaze.1)', 'end(glaze.1)']\n"
     ]
    }
   ],
   "source": [
    "print_state_dictionary(state_dict_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Evaluation From Gold Standard Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Domains"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ";; Rockets domain: A logistic-like domain.\n",
    ";; However, rockets can only fly once (they run out of fuel).\n",
    ";; In problems rrt4 and rrt5 some passengers have to transit\n",
    ";; several times to get to their destination.\n",
    "\n",
    "(define (domain rockets)\n",
    "  (:requirements :strips)\n",
    "  (:predicates (cargo ?x) (rocket ?x) (location ?x)\n",
    "\t       (at ?t ?l) (in ?c ?r) (fuel ?r))\n",
    "\n",
    "  (:action load\n",
    "   :parameters (?c ?r ?l)\n",
    "   :precondition (and (cargo ?c) (rocket ?r) (location ?l)\n",
    "\t\t      (at ?c ?l) (at ?r ?l))\n",
    "   :effect (and (not (at ?c ?l)) (in ?c ?r)))\n",
    "\n",
    "  (:action unload\n",
    "   :parameters (?c ?r ?l)\n",
    "   :precondition (and (cargo ?c) (rocket ?r) (location ?l)\n",
    "\t\t      (in ?c ?r) (at ?r ?l))\n",
    "   :effect (and (not (in ?c ?r)) (at ?c ?l)))\n",
    "\n",
    "  (:action fly\n",
    "   :parameters (?r ?dep ?dst)\n",
    "   :precondition (and (rocket ?r) (location ?dep) (location ?dst)\n",
    "\t\t      (at ?r ?dep) (fuel ?r))\n",
    "   :effect (and (not (at ?r ?dep)) (at ?r ?dst) (not (fuel ?r))))\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-254-d55b0c1f450c>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-254-d55b0c1f450c>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    (define (domain child-snack)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    ";;\n",
    ";; The child-snack domain 2013\n",
    ";;\n",
    ";; This domain is for planning how to make and serve sandwiches for a group of\n",
    ";; children in which some are allergic to gluten. There are two actions for\n",
    ";; making sandwiches from their ingredients. The first one makes a sandwich and\n",
    ";; the second one makes a sandwich taking into account that all ingredients are\n",
    ";; gluten-free. There are also actions to put a sandwich on a tray, to move a tray\n",
    ";; from one place to another and to serve sandwiches.\n",
    ";;\n",
    ";; Problems in this domain define the ingredients to make sandwiches at the initial\n",
    ";; state. Goals consist of having all kids served with a sandwich to which they\n",
    ";; are not allergic.\n",
    ";;\n",
    ";; Author: Raquel Fuentetaja and Toms de la Rosa\n",
    ";;\n",
    ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
    "\n",
    "\n",
    "(define (domain child-snack)\n",
    "(:requirements :typing :equality)\n",
    "(:types child bread-portion content-portion sandwich tray place)\n",
    "(:constants kitchen - place)\n",
    "\n",
    "(:predicates (at_kitchen_bread ?b - bread-portion)\n",
    "\t     (at_kitchen_content ?c - content-portion)\n",
    "     \t     (at_kitchen_sandwich ?s - sandwich)\n",
    "     \t     (no_gluten_bread ?b - bread-portion)\n",
    "       \t     (no_gluten_content ?c - content-portion)\n",
    "      \t     (ontray ?s - sandwich ?t - tray)\n",
    "       \t     (no_gluten_sandwich ?s - sandwich)\n",
    "\t     (allergic_gluten ?c - child)\n",
    "     \t     (not_allergic_gluten ?c - child)\n",
    "\t     (served ?c - child)\n",
    "\t     (waiting ?c - child ?p - place)\n",
    "             (at ?t - tray ?p - place)\n",
    "\t     (notexist ?s - sandwich)\n",
    "  )\n",
    "\n",
    "(:action make_sandwich_no_gluten\n",
    "\t :parameters (?s - sandwich ?b - bread-portion ?c - content-portion)\n",
    "\t :precondition (and (at_kitchen_bread ?b)\n",
    "\t\t\t    (at_kitchen_content ?c)\n",
    "\t\t\t    (no_gluten_bread ?b)\n",
    "\t\t\t    (no_gluten_content ?c)\n",
    "\t\t\t    (notexist ?s))\n",
    "\t :effect (and\n",
    "\t\t   (not (at_kitchen_bread ?b))\n",
    "\t\t   (not (at_kitchen_content ?c))\n",
    "\t\t   (at_kitchen_sandwich ?s)\n",
    "\t\t   (no_gluten_sandwich ?s)\n",
    "                   (not (notexist ?s))\n",
    "\t\t   ))\n",
    "\n",
    "\n",
    "(:action make_sandwich\n",
    "\t :parameters (?s - sandwich ?b - bread-portion ?c - content-portion)\n",
    "\t :precondition (and (at_kitchen_bread ?b)\n",
    "\t\t\t    (at_kitchen_content ?c)\n",
    "                            (notexist ?s)\n",
    "\t\t\t    )\n",
    "\t :effect (and\n",
    "\t\t   (not (at_kitchen_bread ?b))\n",
    "\t\t   (not (at_kitchen_content ?c))\n",
    "\t\t   (at_kitchen_sandwich ?s)\n",
    "                   (not (notexist ?s))\n",
    "\t\t   ))\n",
    "\n",
    "\n",
    "(:action put_on_tray\n",
    "\t :parameters (?s - sandwich ?t - tray)\n",
    "\t :precondition (and  (at_kitchen_sandwich ?s)\n",
    "\t\t\t     (at ?t kitchen))\n",
    "\t :effect (and\n",
    "\t\t   (not (at_kitchen_sandwich ?s))\n",
    "\t\t   (ontray ?s ?t)))\n",
    "\n",
    "\n",
    "(:action serve_sandwich_no_gluten\n",
    " \t:parameters (?s - sandwich ?c - child ?t - tray ?p - place)\n",
    "\t:precondition (and\n",
    "\t\t       (allergic_gluten ?c)\n",
    "\t\t       (ontray ?s ?t)\n",
    "\t\t       (waiting ?c ?p)\n",
    "\t\t       (no_gluten_sandwich ?s)\n",
    "                       (at ?t ?p)\n",
    "\t\t       )\n",
    "\t:effect (and (not (ontray ?s ?t))\n",
    "\t\t     (served ?c)))\n",
    "\n",
    "(:action serve_sandwich\n",
    "\t:parameters (?s - sandwich ?c - child ?t - tray ?p - place)\n",
    "\t:precondition (and (not_allergic_gluten ?c)\n",
    "\t                   (waiting ?c ?p)\n",
    "\t\t\t   (ontray ?s ?t)\n",
    "\t\t\t   (at ?t ?p))\n",
    "\t:effect (and (not (ontray ?s ?t))\n",
    "\t\t     (served ?c)))\n",
    "\n",
    "(:action move_tray\n",
    "\t :parameters (?t - tray ?p1 ?p2 - place)\n",
    "\t :precondition (and (at ?t ?p1))\n",
    "\t :effect (and (not (at ?t ?p1))\n",
    "\t\t      (at ?t ?p2)))\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
